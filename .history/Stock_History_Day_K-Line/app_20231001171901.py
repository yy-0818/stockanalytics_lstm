import streamlit as st
import pandas as pd
import numpy as np
from keras.models import load_model
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import os


plt.style.use('default')


st.set_page_config(
    page_title = 'Real-Time Stock Price Prediction',
    page_icon = 'ğŸ“‹',
    layout="wide",
    initial_sidebar_state="expanded",
)


# åŠ è½½è‚¡ç¥¨æ•°æ®
@st.cache_data
def load_stock_data():
    data = pd.read_csv('.\Stock_History_Day_K-Line\è‹¹æœ.csv')  # æ›¿æ¢ä¸ºä½ çš„è‚¡ç¥¨æ•°æ®æ–‡ä»¶
    # data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'])
    # X_test_set = data.iloc[:,4:5].values
    return data


# åŠ è½½é¢„æµ‹æ¨¡å‹
@st.cache_data
def load_prediction_model(model_name):
    model_path = os.path.join('.\Stock_History_Day_K-Line\Model', f'{model_name}.h5')
    model = load_model(model_path)
    return model


# åˆ›å»ºStreamlitåº”ç”¨ç¨‹åº
st.markdown("<h1 style='text-align: center; color: black;'>åŸºäº LSTM æ¨¡å‹è‚¡ç¥¨å¸‚åœºåˆ†æä¸é¢„æµ‹ğŸ“ˆ</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center; color: black;'>Stock Market Analysis ğŸ“ˆ + Prediction using LSTM</h4>", unsafe_allow_html=True)



# sidebarä¾§è¾¹æ ï¼šç”¨æˆ·è¾“å…¥å‚æ•°
def user_input_features():
    st.sidebar.header('è®¾ç½®å‚æ•°ğŸ“')
    st.sidebar.write('User input parameters below â¬‡ï¸')
    hashtag = st.sidebar.text_input('è¾“å…¥hashtag', value='', key='hashtag_input')
    button = st.sidebar.button('Get Data')

    model_path = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹",('RNN', 'LSTM'),key='model_selection')


    a9 = st.sidebar.selectbox("Agent Status?", ('Happy','Sad','Normal'))
    output = [model_path,a9]
    return output
    
outputdf = user_input_features()
model_name = user_input_features()[0]


# åŠ è½½è‚¡ç¥¨æ•°æ®
stock_data = load_stock_data()
stock_data
# åŠ è½½é¢„æµ‹æ¨¡å‹
model = load_prediction_model()

# 2. é€‰æ‹©éœ€è¦çš„ç‰¹å¾ï¼ˆæ”¶ç›˜ï¼‰å¹¶è¿›è¡Œå½’ä¸€åŒ–
X_train_set = stock_data[['æ”¶ç›˜']].values.astype(float)
scaler = MinMaxScaler()
X_train_set = scaler.fit_transform(X_train_set)
# X_train_set

# æå–æ”¶ç›˜å€¼
X_test_set = load_stock_data().iloc[:,4:5].values

#å–å‡ºå‡ å¤©å‰è‚¡ä»·æ¥å»ºç«‹æˆç‰¹å¾å’Œæ ‡ç­¾æ•°æ®é›†
def create_dataset(ds, look_back=1):
    X_data, Y_data = [],[]
    for i in range(len(ds)-look_back):
        X_data.append(ds[i:(i+look_back), 0])
        Y_data.append(ds[i+look_back, 0])
    return np.array(X_data), np.array(Y_data)
look_back = 60

# åˆ†å‰²æˆç‰¹å¾æ•°æ®å’Œæ ‡ç­¾æ•°æ®
X_train, Y_train = create_dataset(X_train_set, look_back)
# è½¬æ¢æˆ(æ ·æœ¬æ•°, æ—¶æ­¥, ç‰¹å¾)å¼ é‡  
X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))

# äº§ç”Ÿæ ‡ç­¾æ•°æ®




# ä¸»å‡½æ•°
def main():
    # åŠ è½½é€‰å®šçš„æ¨¡å‹
    model = load_prediction_model(model_name)

if __name__ == "__main__":
    main()